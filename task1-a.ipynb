{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e230ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "proj_root = os.path.abspath(\".\")  # your project root\n",
    "if proj_root not in sys.path:\n",
    "    sys.path.insert(0, proj_root)\n",
    "import torch\n",
    "print(\"Project root:\", proj_root)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf774b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "import json\n",
    "# Pruning pipeline functions\n",
    "from pruning.unstructured_pruning import (\n",
    "    run_sensitivity_analysis,\n",
    "    analyze_sensitivity,\n",
    "    apply_pruning_masks_sparse,\n",
    "    verify_masks_coo,\n",
    "    finetune_pruned_model,\n",
    "    profile_pruned_model,\n",
    ")\n",
    "\n",
    "from pruning.utils import evaluate_accuracy\n",
    "\n",
    "# Datasets\n",
    "from data.dataset import (\n",
    "    cifar10_trainloader,\n",
    "    ciaf10_testloader,\n",
    "    cifar100_trainloader,\n",
    "    ciaf100_testloader,\n",
    ")\n",
    "\n",
    "# Model\n",
    "from models.vgg_16_bn import get_model\n",
    "\n",
    "batch_size = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86742676",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"cifar10\": {\n",
    "        \"trainloader\": cifar10_trainloader(batch_size=batch_size),\n",
    "        \"testloader\": ciaf10_testloader(batch_size=batch_size)\n",
    "    },\n",
    "    \"cifar100\": {\n",
    "        \"trainloader\": cifar100_trainloader(batch_size=batch_size),\n",
    "        \"testloader\": ciaf100_testloader(batch_size=batch_size)\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = datasets[\"cifar10\"][\"testloader\"]\n",
    "model = get_model()\n",
    "profile_results = profile_pruned_model(model, testloader, device, \"cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e705163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_pipeline(dataset_name):\n",
    "    print(f\"\\nRunning pipeline for {dataset_name}\\n\")\n",
    "    \n",
    "    trainloader = datasets[dataset_name][\"trainloader\"]\n",
    "    testloader = datasets[dataset_name][\"testloader\"]\n",
    "    \n",
    "    # 1. Load model\n",
    "    model = get_model()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 2. Sensitivity analysis\n",
    "    sensitivity_csv = f\"results/sensitivity_layerwise_{dataset_name}.csv\"\n",
    "    df_sensitivity = run_sensitivity_analysis(model, testloader, device, save_path=sensitivity_csv)\n",
    "    print(f\"Sensitivity CSV saved at {sensitivity_csv}\")\n",
    "    \n",
    "    # 3. Analyze & plan sparsity\n",
    "    overall_sparsity, sparsity_plan = analyze_sensitivity(sensitivity_csv, dataset_name, model)\n",
    "    print(f\"Overall estimated sparsity for {dataset_name}: {overall_sparsity*100:.2f}%\")\n",
    "    \n",
    "    # 4. Apply pruning masks & generate sparse COO\n",
    "    mask_dict, sparse_weights_dict = apply_pruning_masks_sparse(\n",
    "        model,\n",
    "        sparsity_plan_csv=f\"results/plans/sparsity_plan_{dataset_name}.csv\",\n",
    "        dataset_name=dataset_name,\n",
    "        target_sparsity=overall_sparsity,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # 5. Verify masks\n",
    "    verification_log = verify_masks_coo(\n",
    "        mask_path=f\"results/pruning_masks/{dataset_name}_unstructured_mask.pt\",\n",
    "        sparse_path=f\"results/sparse_weights/{dataset_name}_sparse_weights.pt\"\n",
    "    )\n",
    "    print(f\"Verification log entries: {len(verification_log)}\")\n",
    "    \n",
    "    # 6. Finetune pruned model\n",
    "    finetuned_model_path = f\"results/models/{dataset_name}_vgg16_unstructured_finetuned_{int(overall_sparsity*100)}.pt\"\n",
    "    best_val_acc = finetune_pruned_model(\n",
    "        model,\n",
    "        trainloader=trainloader,\n",
    "        val_loader=testloader,\n",
    "        masks=mask_dict,\n",
    "        device=device,\n",
    "        optimizer_type=\"sgd\",\n",
    "        lr=1e-3,\n",
    "        momentum=0.9,\n",
    "        epochs=5,\n",
    "        save_path=finetuned_model_path\n",
    "    )\n",
    "    print(f\"Best validation accuracy after finetuning {dataset_name}: {best_val_acc:.2f}%\")\n",
    "\n",
    "    finetuned_model = get_model().to(device)\n",
    "    finetuned_model.load_state_dict(torch.load(finetuned_model_path))\n",
    "    profile_results = profile_pruned_model(finetuned_model, testloader, device, dataset_name)\n",
    "    \n",
    "    return df_sensitivity, sparsity_plan, verification_log, finetuned_model_path, profile_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c5f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens_10, plan_10, log_10, finetuned_path_10, profile_10 = run_full_pipeline(\"cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2214a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens_100, plan_100, log_100, finetuned_path_100, profile_100 = run_full_pipeline(\"cifar100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6e17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensitivity_curves(dataset_name, csv_path=None, save_dir=\"plots\", plot_drop=True):\n",
    "    if csv_path is None:\n",
    "        csv_path = f\"sensitivity_layerwise_{dataset_name}.csv\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    for layer, group in df.groupby(\"layer\"):\n",
    "        x = group[\"sparsity_pct\"]\n",
    "        y = group[\"top1_drop\"] if plot_drop else group[\"top1\"]\n",
    "        plt.plot(x, y, marker=\"o\", linewidth=1, markersize=4, label=layer)\n",
    "\n",
    "    plt.xlabel(\"Sparsity (%)\")\n",
    "    plt.ylabel(\"Accuracy Drop (%)\" if plot_drop else \"Top-1 Accuracy (%)\")\n",
    "    plt.title(f\"Layer-wise Sensitivity — {dataset_name}\")\n",
    "    plt.grid(alpha=0.2)\n",
    "    plt.tight_layout()\n",
    "    # place legend outside to avoid overlapping\n",
    "    plt.legend(fontsize=7, bbox_to_anchor=(1.02, 1), loc=\"upper left\", ncol=1)\n",
    "    out_path = os.path.join(save_dir, f\"sensitivity_{dataset_name}.png\")\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    display(Image(out_path))\n",
    "    print(f\"Saved: {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "# Example usage (run after sensitivity CSV exists)\n",
    "plot_sensitivity_curves(\"cifar10\")\n",
    "plot_sensitivity_curves(\"cifar100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Plot assigned per-layer sparsity (bar chart) + computed overall sparsity\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def plot_sparsity_plan(dataset_name, plan_csv=None, model=None, save_dir=\"plots\"):\n",
    "    if plan_csv is None:\n",
    "        plan_csv = f\"plans/sparsity_plan_{dataset_name}.csv\"\n",
    "    plan = pd.read_csv(plan_csv)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Sort by params descending for nicer bars\n",
    "    plan_sorted = plan.sort_values(\"params\", ascending=False).reset_index(drop=True)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.bar(np.arange(len(plan_sorted)), plan_sorted[\"assigned_sparsity\"])\n",
    "    plt.xticks(np.arange(len(plan_sorted)), plan_sorted[\"layer\"], rotation=90, fontsize=8)\n",
    "    plt.xlabel(\"Layer\")\n",
    "    plt.ylabel(\"Assigned Sparsity (%)\")\n",
    "    plt.title(f\"Assigned per-layer sparsity — {dataset_name}\")\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(save_dir, f\"sparsity_plan_{dataset_name}.png\")\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    display(Image(out_path))\n",
    "    print(f\"Saved: {out_path}\")\n",
    "\n",
    "    # compute weighted overall sparsity (sanity-check)\n",
    "    total_params = plan_sorted[\"params\"].sum()\n",
    "    weighted = (plan_sorted[\"params\"] * plan_sorted[\"assigned_sparsity\"] / 100.0).sum()\n",
    "    overall = weighted / total_params\n",
    "    print(f\"Weighted overall sparsity (from plan): {overall*100:.2f}%\")\n",
    "    return out_path, overall\n",
    "\n",
    "# Example usage\n",
    "plot_sparsity_plan(\"cifar10\")\n",
    "plot_sparsity_plan(\"cifar100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeffbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Visualize actual mask sparsity per parameter (post-pruning) and histogram\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def plot_mask_sparsity(dataset_name, mask_path=None, save_dir=\"plots\"):\n",
    "    if mask_path is None:\n",
    "        mask_path = f\"results/pruning_masks/{dataset_name}_unstructured_mask.pt\"\n",
    "    masks = torch.load(mask_path)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    rows = []\n",
    "    for name, mask in masks.items():\n",
    "        total = mask.numel()\n",
    "        zeros = (mask == 0).sum().item()\n",
    "        pct = 100.0 * zeros / total\n",
    "        rows.append((name, total, zeros, pct))\n",
    "    df = pd.DataFrame(rows, columns=[\"name\", \"total_params\", \"num_zero\", \"sparsity_pct\"])\n",
    "    df_sorted = df.sort_values(\"sparsity_pct\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Bar plot: top 40 layers by sparsity (or all if small)\n",
    "    topk = min(40, len(df_sorted))\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.barh(np.arange(topk), df_sorted[\"sparsity_pct\"].values[:topk])\n",
    "    plt.yticks(np.arange(topk), df_sorted[\"name\"].values[:topk], fontsize=8)\n",
    "    plt.xlabel(\"Sparsity (%) (zeros / total)\")\n",
    "    plt.title(f\"Mask sparsity per parameter (top {topk}) — {dataset_name}\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(save_dir, f\"mask_sparsity_{dataset_name}.png\")\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    display(Image(out_path))\n",
    "    print(f\"Saved: {out_path}\")\n",
    "\n",
    "    # Histogram of sparsity across layers\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(df[\"sparsity_pct\"], bins=20)\n",
    "    plt.xlabel(\"Layer sparsity (%)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Sparsity distribution across layers — {dataset_name}\")\n",
    "    hist_path = os.path.join(save_dir, f\"mask_sparsity_hist_{dataset_name}.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(hist_path, dpi=200)\n",
    "    plt.close()\n",
    "    display(Image(hist_path))\n",
    "    print(f\"Saved: {hist_path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "df_mask10 = plot_mask_sparsity(\"cifar10\")\n",
    "df_mask100 = plot_mask_sparsity(\"cifar100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de0ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Visualize actual mask sparsity per parameter (post-pruning) and histogram\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def plot_mask_sparsity(dataset_name, mask_path=None, save_dir=\"plots\"):\n",
    "    if mask_path is None:\n",
    "        mask_path = f\"results/pruning_masks/{dataset_name}_unstructured_mask.pt\"\n",
    "    masks = torch.load(mask_path)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    rows = []\n",
    "    for name, mask in masks.items():\n",
    "        total = mask.numel()\n",
    "        zeros = (mask == 0).sum().item()\n",
    "        pct = 100.0 * zeros / total\n",
    "        rows.append((name, total, zeros, pct))\n",
    "    df = pd.DataFrame(rows, columns=[\"name\", \"total_params\", \"num_zero\", \"sparsity_pct\"])\n",
    "    df_sorted = df.sort_values(\"sparsity_pct\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Bar plot: top 40 layers by sparsity (or all if small)\n",
    "    topk = min(40, len(df_sorted))\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.barh(np.arange(topk), df_sorted[\"sparsity_pct\"].values[:topk])\n",
    "    plt.yticks(np.arange(topk), df_sorted[\"name\"].values[:topk], fontsize=8)\n",
    "    plt.xlabel(\"Sparsity (%) (zeros / total)\")\n",
    "    plt.title(f\"Mask sparsity per parameter (top {topk}) — {dataset_name}\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(save_dir, f\"mask_sparsity_{dataset_name}.png\")\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    display(Image(out_path))\n",
    "    print(f\"Saved: {out_path}\")\n",
    "\n",
    "    # Histogram of sparsity across layers\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(df[\"sparsity_pct\"], bins=20)\n",
    "    plt.xlabel(\"Layer sparsity (%)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Sparsity distribution across layers — {dataset_name}\")\n",
    "    hist_path = os.path.join(save_dir, f\"mask_sparsity_hist_{dataset_name}.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(hist_path, dpi=200)\n",
    "    plt.close()\n",
    "    display(Image(hist_path))\n",
    "    print(f\"Saved: {hist_path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "df_mask10 = plot_mask_sparsity(\"cifar10\")\n",
    "df_mask100 = plot_mask_sparsity(\"cifar100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d81580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Show sensitivity plot image files that were saved earlier (if you just want to display)\n",
    "from IPython.display import Image, display\n",
    "display(Image(\"plots/sensitivity_cifar10.png\"))\n",
    "display(Image(\"plots/sensitivity_cifar100.png\"))\n",
    "display(Image(\"plots/sparsity_plan_cifar10.png\"))\n",
    "display(Image(\"plots/sparsity_plan_cifar100.png\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
