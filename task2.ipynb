{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4b4b873",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178ab447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fatim_Sproj\\anaconda3\\envs\\bacp\\lib\\site-packages\\torch\\cuda\\__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from data.dataset import (\n",
    "    cifar10_trainloader,\n",
    "    ciaf10_testloader,\n",
    "    cifar100_trainloader,\n",
    "    ciaf100_testloader,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Subset\n",
    "import random\n",
    "from pruning.structured_pruning import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e4822",
   "metadata": {},
   "source": [
    "### Cifar10 model and loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aada3faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train10 = cifar10_trainloader()\n",
    "test10= ciaf10_testloader()\n",
    "train100 = cifar100_trainloader()\n",
    "test100 =  ciaf100_testloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09230561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Fatim_Sproj/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Using Sparsity Plan:\n",
      "features.0     64.644968\n",
      "features.3     64.644968\n",
      "features.7     64.644968\n",
      "features.10    64.644968\n",
      "features.14    64.644968\n",
      "features.17    64.644968\n",
      "features.20    64.644968\n",
      "features.24    64.644968\n",
      "features.27    64.644968\n",
      "features.30    64.644968\n",
      "features.34    64.644968\n",
      "features.37    64.644968\n",
      "features.40    64.644968\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg16_bn\", pretrained=True)\n",
    "original_model = deepcopy(model)\n",
    "model.to(device)\n",
    "\n",
    "train_loader = cifar10_trainloader()\n",
    "test_loader = ciaf10_testloader()\n",
    "\n",
    "random.seed(42)\n",
    "calib_indices = random.sample(range(len(train_loader.dataset)), 512)\n",
    "calib_subset = Subset(train_loader.dataset, calib_indices)\n",
    "calib_loader = torch.utils.data.DataLoader(calib_subset, batch_size=128)\n",
    "\n",
    "plan_file_path = r\"C:\\Users\\Fatim_Sproj\\Desktop\\Fatim\\Spring 2025\\aiedge\\Pruning\\results\\sensitivity_layerwise_cifar10.csv\"\n",
    "sparsity_plan = generate_plan_for_target_sparsity(plan_file_path, original_model, 0.73)\n",
    "\n",
    "print(\"\\nUsing Sparsity Plan:\")\n",
    "print(pd.Series(sparsity_plan).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c84de6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing original model to get stable channel rankings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fatim_Sproj\\anaconda3\\envs\\bacp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.593e+00, tolerance: 2.472e+00\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Fatim_Sproj\\anaconda3\\envs\\bacp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.766e+00, tolerance: 4.422e-01\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Fatim_Sproj\\anaconda3\\envs\\bacp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.189e-02, tolerance: 2.683e-02\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing layer: features.3\n",
      "Target: Keep 22 / 64 channels\n",
      "\n",
      "Processing layer: features.7\n",
      "Target: Keep 22 / 64 channels\n",
      "\n",
      "Processing layer: features.10\n",
      "Target: Keep 45 / 128 channels\n",
      "\n",
      "Processing layer: features.14\n",
      "Target: Keep 45 / 128 channels\n",
      "\n",
      "Processing layer: features.17\n",
      "Target: Keep 90 / 256 channels\n",
      "\n",
      "Processing layer: features.20\n",
      "Target: Keep 90 / 256 channels\n",
      "\n",
      "Processing layer: features.24\n",
      "Target: Keep 90 / 256 channels\n",
      "\n",
      "Processing layer: features.27\n",
      "Target: Keep 181 / 512 channels\n",
      "\n",
      "Processing layer: features.30\n",
      "Target: Keep 181 / 512 channels\n",
      "\n",
      "Processing layer: features.34\n",
      "Target: Keep 181 / 512 channels\n",
      "\n",
      "Processing layer: features.37\n",
      "Target: Keep 181 / 512 channels\n",
      "\n",
      "Processing layer: features.40\n",
      "Target: Keep 181 / 512 channels\n",
      "\n",
      "Pruning complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAnalyzing original model to get stable channel rankings...\")\n",
    "original_activations_in, original_activations_out = collect_inputs_outputs(original_model, calib_loader, device)\n",
    "original_unf_x = unfold_activations(original_activations_in, original_model)\n",
    "channel_saliency_scores = get_channel_saliency_scores(original_model, original_unf_x, original_activations_out)\n",
    "\n",
    "prunable_convs = [name for name, mod in model.named_modules() if isinstance(mod, nn.Conv2d)][1:]\n",
    "\n",
    "for layer_name in prunable_convs:\n",
    "    print(f\"\\nProcessing layer: {layer_name}\")\n",
    "    \n",
    "    current_layer = model.get_submodule(layer_name)\n",
    "    sparsity = sparsity_plan.get(layer_name, 0.0) / 100.0\n",
    "    num_channels_to_keep = max(16, int(current_layer.in_channels * (1.0 - sparsity)))\n",
    "    \n",
    "    print(f\"Target: Keep {num_channels_to_keep} / {current_layer.in_channels} channels\")\n",
    "    \n",
    "    saliency = channel_saliency_scores[layer_name]\n",
    "    kept_indices = np.argsort(-saliency)[:num_channels_to_keep]\n",
    "    \n",
    "    reconstruct_and_prune_prev(model, original_unf_x, original_activations_out, layer_name, kept_indices, device)\n",
    "    \n",
    "print(\"\\nPruning complete.\")\n",
    "\n",
    "final_conv_channels = None\n",
    "for layer in reversed(model.features):\n",
    "    if isinstance(layer, nn.BatchNorm2d):\n",
    "        final_conv_channels = layer.num_features\n",
    "        break\n",
    "\n",
    "if final_conv_channels:\n",
    "    model.classifier[0] = nn.Linear(final_conv_channels, model.classifier[0].out_features)\n",
    "    model.to(device)\n",
    "else:\n",
    "    print(\"Error: Could not find final BatchNorm layer to resize classifier.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4f8e275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Structured Sparsity: 80.92%\n",
      "Accuracy after pruning: 13.05%\n",
      "\n",
      "Starting fine-tuning...\n",
      "Epoch 1/40 — Accuracy: 78.54%\n",
      "Epoch 2/40 — Accuracy: 78.97%\n",
      "Epoch 3/40 — Accuracy: 78.39%\n",
      "Epoch 4/40 — Accuracy: 79.64%\n",
      "Epoch 5/40 — Accuracy: 80.90%\n",
      "Epoch 6/40 — Accuracy: 82.58%\n",
      "Epoch 7/40 — Accuracy: 82.37%\n",
      "Epoch 8/40 — Accuracy: 83.88%\n",
      "Epoch 9/40 — Accuracy: 83.88%\n",
      "Epoch 10/40 — Accuracy: 84.51%\n",
      "Epoch 11/40 — Accuracy: 84.20%\n",
      "Epoch 12/40 — Accuracy: 82.09%\n",
      "Epoch 13/40 — Accuracy: 83.89%\n",
      "Epoch 14/40 — Accuracy: 85.65%\n",
      "Epoch 15/40 — Accuracy: 85.18%\n",
      "Epoch 16/40 — Accuracy: 85.09%\n",
      "Epoch 17/40 — Accuracy: 83.22%\n",
      "Epoch 18/40 — Accuracy: 85.32%\n",
      "Epoch 19/40 — Accuracy: 84.30%\n",
      "Epoch 20/40 — Accuracy: 85.21%\n",
      "Epoch 21/40 — Accuracy: 85.58%\n",
      "Epoch 22/40 — Accuracy: 85.09%\n",
      "Epoch 23/40 — Accuracy: 86.70%\n",
      "Epoch 24/40 — Accuracy: 86.49%\n",
      "Epoch 25/40 — Accuracy: 86.62%\n",
      "Epoch 26/40 — Accuracy: 87.23%\n",
      "Epoch 27/40 — Accuracy: 87.54%\n",
      "Epoch 28/40 — Accuracy: 87.45%\n",
      "Epoch 29/40 — Accuracy: 87.71%\n",
      "Epoch 30/40 — Accuracy: 87.69%\n",
      "Epoch 31/40 — Accuracy: 87.83%\n",
      "Epoch 32/40 — Accuracy: 87.94%\n",
      "Epoch 33/40 — Accuracy: 87.92%\n",
      "Epoch 34/40 — Accuracy: 88.12%\n",
      "Epoch 35/40 — Accuracy: 87.97%\n",
      "Epoch 36/40 — Accuracy: 88.07%\n",
      "Epoch 37/40 — Accuracy: 87.89%\n",
      "Epoch 38/40 — Accuracy: 87.95%\n",
      "Epoch 39/40 — Accuracy: 88.14%\n",
      "Epoch 40/40 — Accuracy: 88.01%\n",
      "\n",
      "--- Final Results ---\n",
      "Final Accuracy: 88.01%\n",
      "Overall Sparsity: 80.92%\n"
     ]
    }
   ],
   "source": [
    "sparsity = calculate_structured_sparsity(original_model, model)\n",
    "print(f\"\\nOverall Structured Sparsity: {sparsity*100:.2f}%\")\n",
    "pre_finetune_acc = evaluate_accuracy(model, test_loader, device)\n",
    "print(f\"Accuracy after pruning: {pre_finetune_acc:.2f}%\")\n",
    "\n",
    "print(\"\\nStarting fine-tuning...\")\n",
    "finetuned_model = finetune_model(model, train_loader, test_loader, device)\n",
    "\n",
    "print(\"\\n--- Final Results ---\")\n",
    "final_accuracy = evaluate_accuracy(finetuned_model, test_loader, device)\n",
    "print(f\"Final Accuracy: {final_accuracy:.2f}%\")\n",
    "print(f\"Overall Sparsity: {sparsity*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5db58182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model weights saved successfully to: cifar10_vgg16_pruned_80sparsity.pt\n"
     ]
    }
   ],
   "source": [
    "sparsity_int = int(sparsity * 100)\n",
    "save_path = f\"cifar10_vgg16_pruned_{sparsity_int}sparsity.pt\"\n",
    "torch.save(finetuned_model, save_path)\n",
    "print(f\"\\nModel weights saved successfully to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd070bf1",
   "metadata": {},
   "source": [
    "### Cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca28324a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Fatim_Sproj/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Using Sparsity Plan:\n",
      "features.0     64.644968\n",
      "features.3     64.644968\n",
      "features.7     64.644968\n",
      "features.10    64.644968\n",
      "features.14    64.644968\n",
      "features.17    64.644968\n",
      "features.20    64.644968\n",
      "features.24    64.644968\n",
      "features.27    64.644968\n",
      "features.30    64.644968\n",
      "features.34    64.644968\n",
      "features.37    64.644968\n",
      "features.40    64.644968\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_vgg16_bn\", pretrained=True)\n",
    "original_model = deepcopy(model)\n",
    "model.to(device)\n",
    "\n",
    "train_loader = cifar100_trainloader()\n",
    "test_loader = ciaf100_testloader()\n",
    "\n",
    "random.seed(42)\n",
    "calib_indices = random.sample(range(len(train_loader.dataset)), 512)\n",
    "calib_subset = Subset(train_loader.dataset, calib_indices)\n",
    "calib_loader = torch.utils.data.DataLoader(calib_subset, batch_size=128)\n",
    "\n",
    "plan_file_path = r\"C:\\Users\\Fatim_Sproj\\Desktop\\Fatim\\Spring 2025\\aiedge\\Pruning\\results\\sensitivity_layerwise_cifar100.csv\"\n",
    "sparsity_plan = generate_plan_for_target_sparsity(plan_file_path, original_model, 0.73)\n",
    "\n",
    "print(\"\\nUsing Sparsity Plan:\")\n",
    "print(pd.Series(sparsity_plan).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99357329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing original model to get stable channel rankings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fatim_Sproj\\anaconda3\\envs\\bacp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e+01, tolerance: 1.200e+01\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing layer: features.3\n",
      "Target: Keep 22 / 64 channels\n",
      "\n",
      "Processing layer: features.7\n",
      "Target: Keep 22 / 64 channels\n",
      "\n",
      "Processing layer: features.10\n",
      "Target: Keep 45 / 128 channels\n",
      "\n",
      "Processing layer: features.14\n",
      "Target: Keep 45 / 128 channels\n",
      "\n",
      "Processing layer: features.17\n",
      "Target: Keep 90 / 256 channels\n",
      "\n",
      "Processing layer: features.20\n",
      "Target: Keep 90 / 256 channels\n",
      "\n",
      "Processing layer: features.24\n",
      "Target: Keep 90 / 256 channels\n",
      "\n",
      "Processing layer: features.27\n",
      "Target: Keep 181 / 512 channels\n",
      "\n",
      "Processing layer: features.30\n",
      "Target: Keep 181 / 512 channels\n",
      "\n",
      "Processing layer: features.34\n",
      "Target: Keep 181 / 512 channels\n",
      "\n",
      "Processing layer: features.37\n",
      "Target: Keep 181 / 512 channels\n",
      "\n",
      "Processing layer: features.40\n",
      "Target: Keep 181 / 512 channels\n",
      "\n",
      "Pruning complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAnalyzing original model to get stable channel rankings...\")\n",
    "original_activations_in, original_activations_out = collect_inputs_outputs(original_model, calib_loader, device)\n",
    "original_unf_x = unfold_activations(original_activations_in, original_model)\n",
    "channel_saliency_scores = get_channel_saliency_scores(original_model, original_unf_x, original_activations_out)\n",
    "\n",
    "prunable_convs = [name for name, mod in model.named_modules() if isinstance(mod, nn.Conv2d)][1:]\n",
    "\n",
    "for layer_name in prunable_convs:\n",
    "    print(f\"\\nProcessing layer: {layer_name}\")\n",
    "    \n",
    "    current_layer = model.get_submodule(layer_name)\n",
    "    sparsity = sparsity_plan.get(layer_name, 0.0) / 100.0\n",
    "    num_channels_to_keep = max(16, int(current_layer.in_channels * (1.0 - sparsity)))\n",
    "    \n",
    "    print(f\"Target: Keep {num_channels_to_keep} / {current_layer.in_channels} channels\")\n",
    "    \n",
    "    saliency = channel_saliency_scores[layer_name]\n",
    "    kept_indices = np.argsort(-saliency)[:num_channels_to_keep]\n",
    "    \n",
    "    reconstruct_and_prune_prev(model, original_unf_x, original_activations_out, layer_name, kept_indices, device)\n",
    "    \n",
    "print(\"\\nPruning complete.\")\n",
    "\n",
    "final_conv_channels = None\n",
    "for layer in reversed(model.features):\n",
    "    if isinstance(layer, nn.BatchNorm2d):\n",
    "        final_conv_channels = layer.num_features\n",
    "        break\n",
    "\n",
    "if final_conv_channels:\n",
    "    model.classifier[0] = nn.Linear(final_conv_channels, model.classifier[0].out_features)\n",
    "    model.to(device)\n",
    "else:\n",
    "    print(\"Error: Could not find final BatchNorm layer to resize classifier.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a82dcde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Structured Sparsity: 80.68%\n",
      "Accuracy after pruning: 1.18%\n",
      "\n",
      "Starting fine-tuning...\n",
      "Epoch 1/40 — Accuracy: 9.43%\n",
      "Epoch 2/40 — Accuracy: 20.31%\n",
      "Epoch 3/40 — Accuracy: 30.13%\n",
      "Epoch 4/40 — Accuracy: 35.61%\n",
      "Epoch 5/40 — Accuracy: 38.98%\n",
      "Epoch 6/40 — Accuracy: 41.36%\n",
      "Epoch 7/40 — Accuracy: 43.50%\n",
      "Epoch 8/40 — Accuracy: 44.31%\n",
      "Epoch 9/40 — Accuracy: 44.89%\n",
      "Epoch 10/40 — Accuracy: 45.53%\n",
      "Epoch 11/40 — Accuracy: 47.34%\n",
      "Epoch 12/40 — Accuracy: 49.61%\n",
      "Epoch 13/40 — Accuracy: 47.12%\n",
      "Epoch 14/40 — Accuracy: 47.95%\n",
      "Epoch 15/40 — Accuracy: 49.98%\n",
      "Epoch 16/40 — Accuracy: 48.00%\n",
      "Epoch 17/40 — Accuracy: 50.19%\n",
      "Epoch 18/40 — Accuracy: 50.99%\n",
      "Epoch 19/40 — Accuracy: 49.68%\n",
      "Epoch 20/40 — Accuracy: 50.78%\n",
      "Epoch 21/40 — Accuracy: 50.14%\n",
      "Epoch 22/40 — Accuracy: 51.83%\n",
      "Epoch 23/40 — Accuracy: 51.82%\n",
      "Epoch 24/40 — Accuracy: 52.28%\n",
      "Epoch 25/40 — Accuracy: 51.94%\n",
      "Epoch 26/40 — Accuracy: 52.00%\n",
      "Epoch 27/40 — Accuracy: 52.72%\n",
      "Epoch 28/40 — Accuracy: 53.38%\n",
      "Epoch 29/40 — Accuracy: 53.07%\n",
      "Epoch 30/40 — Accuracy: 53.48%\n",
      "Epoch 31/40 — Accuracy: 54.18%\n",
      "Epoch 32/40 — Accuracy: 54.42%\n",
      "Epoch 33/40 — Accuracy: 54.50%\n",
      "Epoch 34/40 — Accuracy: 54.72%\n",
      "Epoch 35/40 — Accuracy: 54.69%\n",
      "Epoch 36/40 — Accuracy: 54.81%\n",
      "Epoch 37/40 — Accuracy: 54.79%\n",
      "Epoch 38/40 — Accuracy: 54.70%\n",
      "Epoch 39/40 — Accuracy: 54.55%\n",
      "Epoch 40/40 — Accuracy: 54.47%\n",
      "\n",
      "--- Final Results ---\n",
      "Final Accuracy: 54.47%\n",
      "Overall Sparsity: 80.68%\n"
     ]
    }
   ],
   "source": [
    "sparsity = calculate_structured_sparsity(original_model, model)\n",
    "print(f\"\\nOverall Structured Sparsity: {sparsity*100:.2f}%\")\n",
    "pre_finetune_acc = evaluate_accuracy(model, test_loader, device)\n",
    "print(f\"Accuracy after pruning: {pre_finetune_acc:.2f}%\")\n",
    "\n",
    "print(\"\\nStarting fine-tuning...\")\n",
    "finetuned_model = finetune_model(model, train_loader, test_loader, device)\n",
    "\n",
    "print(\"\\n--- Final Results ---\")\n",
    "final_accuracy = evaluate_accuracy(finetuned_model, test_loader, device)\n",
    "print(f\"Final Accuracy: {final_accuracy:.2f}%\")\n",
    "print(f\"Overall Sparsity: {sparsity*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34a351b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model weights saved successfully to: cifar100_vgg16_pruned_80sparsity.pt\n"
     ]
    }
   ],
   "source": [
    "sparsity_int = int(sparsity * 100)\n",
    "save_path = f\"cifar100_vgg16_pruned_{sparsity_int}sparsity.pt\"\n",
    "torch.save(finetuned_model, save_path)\n",
    "print(f\"\\nModel weights saved successfully to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bacp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
